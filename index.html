<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="RTV-Bench: Benchmarking MLLM Continuous Perception, Understanding and Reasoning through Real-Time Video">
  <meta name="keywords" content="RTV-Bench, MLLM, Video Understanding, Real-Time Video, Benchmark">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>RTV-Bench: Benchmarking MLLM Continuous Perception, Understanding and Reasoning through Real-Time Video</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  
  <!-- MathJax for LaTeX rendering -->
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      }
    };
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://github.com/LJungang/RTV-Bench">
      <span class="icon">
          <i class="fab fa-github"></i>
      </span>
      </a>
    </div>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">$\mathcal{RTV}\text{-}Bench$: Benchmarking MLLM Continuous Perception, Understanding and Reasoning through Real-Time Video</h1>
          
          <div class="is-size-5 publication-authors" style="margin-top: 1.5rem;">
            <span class="author-block">
              Shuhang Xun<sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=f1J2jZkAAAAJ">Sicheng Tao</a><sup>2*</sup>,</span>
            <span class="author-block">
              <a href="https://github.com/LJungang">Jungang Li</a><sup>2,3*‚Ä†</sup>,</span>
            <span class="author-block">
              Yibo Shi<sup>4</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=c51a_HwAAAAJ">Zhixin Lin</a><sup>5</sup>,</span>
            <span class="author-block">
              Zhanhui Zhu<sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=26yPSEcAAAAJ">Yibo Yan</a><sup>2,3</sup>,</span>
            <span class="author-block">
              <a href="https://kyrie-li11.github.io/">Hanqian Li</a><sup>2</sup>,</span>
            <span class="author-block">
              Linghao Zhang<sup>5</sup>,</span>
            <span class="author-block">
              Shikang Wang<sup>6</sup>,</span>
            <span class="author-block">
              Yixin Liu<sup>1</sup>,</span>
            <span class="author-block">
              Hanbo Zhang<sup>7</sup>,</span>
            <span class="author-block">
              Ying Ma<sup>1‚Ä°</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=dbBKbXoAAAAJ">Xuming Hu</a><sup>2,3</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors" style="margin-top: 1.5rem; line-height: 2;">
            <span class="author-block"><sup>1</sup>HIT</span>,
            <span class="author-block"><sup>2</sup>HKUST(GZ)</span>,
            <span class="author-block"><sup>3</sup>HKUST</span>,
            <span class="author-block"><sup>4</sup>XJTU</span>,
            <span class="author-block"><sup>5</sup>SDU</span>,
            <span class="author-block"><sup>6</sup>CityU</span>,
            <span class="author-block"><sup>7</sup>HUST</span>
          
            <div style="margin-top: 0.75rem; padding-top: 0.75rem; border-top: 1px solid rgba(0,0,0,0.1); font-size: 0.9em; color: #666;">
              <span class="author-block">*Equal Contribution</span>
              <span class="author-block" style="margin-left: 1rem;">‚Ä†Project Leader</span>
              <span class="author-block" style="margin-left: 1rem;">‚Ä°Corresponding Author</span>
            </div>
          </div>
          

          <div class="publication-venue" style="margin-top: 2rem;">
            <div style="font-size: 1.1em; margin-bottom: 0.75rem;">
              <strong>üéâ Accepted to</strong>
            </div>
            <div style="font-size: 1.3em; font-weight: bold; margin-bottom: 0.5rem; line-height: 1.3;">
              39th Conference on Neural Information Processing Systems (NeurIPS 2025)
            </div>
            <div style="font-size: 1em; opacity: 0.95;">
              Track on Datasets and Benchmarks
            </div>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Paper Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2505.02064"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- HuggingFace Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/xunsh/RTV-Bench"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-database"></i>
                  </span>
                  <span>ü§ó HuggingFace</span>
                </a>
              </span>
              <!-- ModelScope Link. -->
              <span class="link-block">
                <a href="https://www.modelscope.cn/datasets/Jungang/RTV-Bench"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-database"></i>
                  </span>
                  <span>ü§ñ ModelScope</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/LJungang/RTV-Bench"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./asset/1_examples.png" alt="RTV-Bench Examples" style="width: 100%; border-radius: 10px;">
      <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
        If our project helps you, please give us a star ‚≠ê on GitHub to support us. ü•∏ü•∏
      </h2>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div class="has-text-centered">
        <h2 class="title is-3">üî• News</h2>
        <div class="content has-text-left" style="max-width: 800px; margin: 0 auto;">
          <ul>
            <li><strong>2025-09-20</strong> üéâüéâüéâ Our paper has been accepted by NeurIPS 2025, we will update our dataset and code for community as soon as possible~</li>
            <li><strong>2025-06-27</strong> üéâ We update core code for evaluation.</li>
            <li><strong>2025-05-17</strong> üéâ We have released the label json, which is named <code>QA.json</code>.</li>
            <li><strong>2025-05-04</strong> üéâ We released the paper $\mathcal{RTV}\text{-}Bench$: <a href="https://arxiv.org/abs/2505.02064">Benchmarking MLLM Continuous Perception, Understanding and Reasoning through Real-Time Video</a>.</li>
            <li><strong>2025-05-03</strong> üåü We are happy to release the $\mathcal{RTV}\text{-}Bench$. You can find it on <a href="https://huggingface.co/datasets/xunsh/RTV-Bench">HuggingFace</a> or <a href="https://www.modelscope.cn/datasets/Jungang/RTV-Bench">ModelScope</a>.</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Overview. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">üëÄ $\mathcal{RTV}\text{-}Bench$ Overview</h2>
        <div class="content has-text-justified">
          <p>
            We introduce $\mathcal{RTV}\text{-}Bench$, a fine-grained benchmark for MLLM real-time video analysis, which contains <strong>552</strong> videos (167.2 hours) and <strong>4,631</strong> high-quality QA pairs. We evaluated leading MLLMs, including proprietary (<i>e.g.</i> GPT-4o, Gemini 2.0), open-source offline (<i>e.g.</i> Qwen2.5-VL, VideoLLaMA3), and open-source real-time (<i>e.g.</i> VITA-1.5, InternLM-XComposer2.5-OmniLive) models. Experiment results show open-source real-time models largely outperform offline ones but still trail top proprietary models. Our analysis also reveals that larger model size or higher frame sampling rates do not significantly boost $\mathcal{RTV}\text{-}Bench$ performance, sometimes causing slight decreases. This underscores the need for better model architectures optimized for video stream processing and long sequences to advance real-time video analysis with MLLMs.
          </p>
          <p>
            $\mathcal{RTV}\text{-}Bench$ includes three key principles:
          </p>
          <ul>
            <li><strong>Multi-Timestamp Question Answering (MTQA)</strong>, where answers evolve with scene changes;</li>
            <li><strong>Hierarchical Question Structure</strong>, combining basic and advanced queries; and</li>
            <li><strong>Multi-dimensional Evaluation</strong>, assessing the ability of continuous perception, understanding, and reasoning.</li>
          </ul>
        </div>
      </div>
    </div>
    <!--/ Overview. -->

    <!-- Dataset Statistics. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h3 class="title is-4">Video Categories and Distribution of Question Difficulty and Query Characteristics</h3>
        <img src="./asset/2_dataset_stati.png" alt="Dataset Statistics" style="width: 100%; border-radius: 10px; margin-top: 1rem;">
        <div class="content has-text-justified" style="margin-top: 1rem;">
          <p>
            <strong>(Left)</strong> RTV-Bench covers 3 key domains and 16 sub-class video types.
          </p>
          <p>
            <strong>(Center)</strong> Distribution of question difficulty levels across eight representative task types, measured by percentage-based performance ranges.
          </p>
          <p>
            <strong>(Right)</strong> Distribution of question queries by video length, categorized into Shallow, Moderate, and Deep levels. The bar heights indicate counts, while the line chart overlays query proportions for each duration bucket.
          </p>
        </div>
      </div>
    </div>
    <!--/ Dataset Statistics. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Evaluation Results. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">üîñ Evaluation Results</h2>
        <img src="./asset/3_evaluation.png" alt="Evaluation Results" style="width: 100%; border-radius: 10px; margin-top: 1rem;">
      </div>
    </div>
    <!--/ Evaluation Results. -->

    <!-- Visualization. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">üìä Visualization</h2>
        <img src="./asset/4_visualization.png" alt="Visualization" style="width: 100%; border-radius: 10px; margin-top: 1rem;">
      </div>
    </div>
    <!--/ Visualization. -->

</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">üìë Citation</h2>
    <p>If you find $\mathcal{RTV}\text{-}Bench$ useful for your research and applications, please cite using this BibTeX:</p>
    <pre><code>@inproceedings{xun2025rtv,
  title={RTV-Bench: Benchmarking MLLM Continuous Perception, Understanding and Reasoning through Real-Time Video},
  author={Xun, Shuhang and Tao, Sicheng and Li, Jungang and Shi, Yibo and Lin, Zhixin and Zhu, Zhanhui and Yan, Yibo and Li, Hanqian and Zhang, Linghao and Wang, Shikang and Liu, Yixin and Zhang, Hanbo and Ma, Ying and Hu, Xuming},
  booktitle={Advances in Neural Information Processing Systems},
  volume={38},
  year={2025},
  organization={NeurIPS}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/LJungang/RTV-Bench">
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
